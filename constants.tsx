
import { PythonFile } from './types';

export const PYTHON_CODEBASE: PythonFile[] = [
  {
    path: 'README.md',
    name: 'README.md',
    language: 'markdown',
    content: `# traffic-rl\n\nAdvanced RL traffic signal controller with vehicle diversity, speed simulation, and action masking.\n\n## Features\n- **Speed Simulation**: Vehicles accelerate when green and stop when red. Throughput depends on exit speed.\n- **Sophisticated Env**: Variable arrival rates and multiple vehicle types (Car, Truck, Bike).\n- **Action Masking**: Prevents rapid light flickering using minimum phase duration.\n- **Visualization**: Matplotlib-based real-time state rendering.\n\n## Quick run\n1. Install: \`pip install -r requirements.txt\`\n2. Run tests: \`pytest\`\n3. Train: \`python train.py --episodes 100\`\n4. Eval: \`python evaluate.py --checkpoint models/dqn_checkpoint.pth --render\``
  },
  {
    path: 'requirements.txt',
    name: 'requirements.txt',
    language: 'text',
    content: `numpy\ntorch\nmatplotlib\npytest`
  },
  {
    path: 'envs/traffic_env.py',
    name: 'traffic_env.py',
    language: 'python',
    content: `import numpy as np\n\nclass TrafficEnv:\n    # (Weight, Max Speed Potential)\n    VEHICLE_TYPES = {\n        "car": (1.0, 1.0),\n        "truck": (2.5, 0.5),\n        "bike": (0.5, 1.2)\n    }\n    \n    def __init__(self, arrival_rates=None):\n        self.n_lanes = 4\n        self.arrival_rates = arrival_rates if arrival_rates else [0.2, 0.2, 0.1, 0.1]\n        self.min_phase_time = 5\n        self.reset()\n\n    def reset(self):\n        # Each queue entry: {"weight": w, "speed": s, "max_speed": ms}\n        self.queues = [[] for _ in range(self.n_lanes)]\n        self.phase = 0 # 0: NS, 1: EW\n        self.steps_in_phase = 0\n        self.steps = 0\n        self.ambulance_lane = -1\n        return self._get_obs()\n\n    def _get_obs(self):\n        lane_counts = np.array([len(q) for q in self.queues])\n        lane_weights = np.array([sum(v['weight'] for v in q) if q else 0 for q in self.queues])\n        avg_speeds = np.array([np.mean([v['speed'] for v in q]) if q else 1.0 for q in self.queues])\n        amb_flag = 1.0 if self.ambulance_lane != -1 else 0.0\n        \n        # Observation shape: 4 (counts) + 4 (weights) + 4 (speeds) + 1 (phase) + 1 (amb) = 14\n        return np.concatenate([\n            lane_counts,\n            lane_weights,\n            avg_speeds,\n            [float(self.phase)],\n            [amb_flag]\n        ])\n\n    def get_action_mask(self):\n        mask = np.ones(2, dtype=np.float32)\n        if self.steps_in_phase < self.min_phase_time:\n            mask[1] = 0.0\n        return mask\n\n    def step(self, action):\n        action_mask = self.get_action_mask()\n        if action_mask[action] == 0: action = 0 \n\n        # Process Action\n        switch_penalty = 0\n        if action == 1:\n            self.phase = 1 - self.phase\n            self.steps_in_phase = 0\n            switch_penalty = 0.5 \n        else:\n            self.steps_in_phase += 1\n\n        # Arrivals\n        for i, rate in enumerate(self.arrival_rates):\n            if np.random.random() < rate:\n                vtype = np.random.choice(list(self.VEHICLE_TYPES.keys()), p=[0.7, 0.1, 0.2])\n                w, ms = self.VEHICLE_TYPES[vtype]\n                self.queues[i].append({"weight": w, "speed": 0.0, "max_speed": ms})\n\n        # Update Speeds and Departures\n        green_lanes = [0, 1] if self.phase == 0 else [2, 3]\n        total_throughput = 0\n        \n        for i in range(self.n_lanes):\n            if i in green_lanes:\n                # Accelerate leading vehicles\n                for j in range(min(len(self.queues[i]), 3)):\n                    v = self.queues[i][j]\n                    v['speed'] = min(v['max_speed'], v['speed'] + 0.25)\n                \n                # Leading vehicle departs if speed is sufficient\n                if self.queues[i] and self.queues[i][0]['speed'] >= 0.5:\n                    departed = self.queues[i].pop(0)\n                    total_throughput += departed['weight']\n            else:\n                # Red light: deceleration/stop\n                for v in self.queues[i]:\n                    v['speed'] = max(0.0, v['speed'] - 0.5)\n\n        self.steps += 1\n        done = self.steps >= 100\n        \n        # Reward Dynamics:\n        # 1. Penalize weighted waiting (sum of weights of stationary vehicles)\n        # 2. Bonus for throughput (weighted sum of departed vehicles)\n        # 3. Penalty for light switching\n        waiting_penalty = sum(v['weight'] for q in self.queues for v in q if v['speed'] < 0.1)\n        reward = (total_throughput * 2.0) - (waiting_penalty * 0.5) - switch_penalty\n\n        # Random ambulance\n        if np.random.random() < 0.03 and self.ambulance_lane == -1:\n            self.ambulance_lane = np.random.randint(0, 4)\n        elif self.ambulance_lane != -1 and not self.queues[self.ambulance_lane]:\n            self.ambulance_lane = -1\n        \n        return self._get_obs(), reward, done, {\n            "action_mask": action_mask,\n            "throughput": total_throughput,\n            "avg_wait": waiting_penalty / (sum(len(q) for q in self.queues) + 1e-6)\n        }\n`
  },
  {
    path: 'train.py',
    name: 'train.py',
    language: 'python',
    content: `from envs.traffic_env import TrafficEnv\nfrom agents.dqn_agent import DQNAgent\nimport argparse\n\ndef run_train(episodes):\n    env = TrafficEnv()\n    # Updated state_dim to 14 to match new observation space\n    agent = DQNAgent(14, 2)\n    \n    for e in range(episodes):\n        state = env.reset()\n        done = False\n        total_reward = 0\n        while not done:\n            mask = env.get_action_mask()\n            action = agent.act(state, action_mask=mask)\n            next_state, reward, done, info = env.step(action)\n            state = next_state\n            total_reward += reward\n        print(f"Ep {e} - Reward: {total_reward:.1f} - Avg Wait: {info['avg_wait']:.2f}")\n\nif __name__ == "__main__":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--episodes', type=int, default=10)\n    args = parser.parse_args()\n    run_train(args.episodes)\n`
  },
  {
    path: 'evaluate.py',
    name: 'evaluate.py',
    language: 'python',
    content: `import torch\nimport argparse\nfrom envs.traffic_env import TrafficEnv\nfrom agents.dqn_agent import DQNAgent\nfrom utils.visualize import TrafficVisualizer\n\ndef evaluate(checkpoint_path, render=False):\n    env = TrafficEnv()\n    agent = DQNAgent(14, 2)\n    if checkpoint_path:\n        # agent.model.load_state_dict(torch.load(checkpoint_path))\n        pass # Mock loading for demo\n    \n    viz = TrafficVisualizer() if render else None\n    \n    for e in range(3):\n        state = env.reset()\n        done = False\n        while not done:\n            mask = env.get_action_mask()\n            action = agent.act(state, action_mask=mask)\n            state, _, done, info = env.step(action)\n            if viz: viz.render(env)\n        print(f"Eval Episode {e+1} Complete")\n\nif __name__ == "__main__":\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--checkpoint', type=str, default=None)\n    parser.add_argument('--render', action='store_true')\n    args = parser.parse_args()\n    evaluate(args.checkpoint, args.render)\n`
  },
  {
    path: 'utils/visualize.py',
    name: 'visualize.py',
    language: 'python',
    content: `import matplotlib.pyplot as plt\nimport numpy as np\n\nclass TrafficVisualizer:\n    def __init__(self):\n        plt.ion()\n        self.fig, self.ax = plt.subplots(figsize=(7, 7))\n\n    def render(self, env):\n        self.ax.clear()\n        self.ax.set_xlim(-12, 12)\n        self.ax.set_ylim(-12, 12)\n        self.ax.set_facecolor('#2d3436')\n        self.ax.set_title(f"RL Traffic Controller | Step: {env.steps} | Phase: {'NS' if env.phase==0 else 'EW'}", color='white')\n        \n        # Draw roads\n        self.ax.axhline(0, color='#636e72', lw=60, zorder=0)\n        self.ax.axvline(0, color='#636e72', lw=60, zorder=0)\n        \n        # Lights\n        ns_color = '#00b894' if env.phase == 0 else '#d63031'\n        ew_color = '#d63031' if env.phase == 0 else '#00b894'\n        self.ax.add_patch(plt.Circle((0, 4), 0.7, color=ns_color, zorder=5))\n        self.ax.add_patch(plt.Circle((4, 0), 0.7, color=ew_color, zorder=5))\n\n        # Vehicles\n        for i, q in enumerate(env.queues):\n            for j, v in enumerate(q):\n                # Position logic based on lane\n                dist = 2.5 + j * 1.5\n                if i == 0: pos = (1, dist)      # North (Inbound)\n                elif i == 1: pos = (-1, -dist)   # South (Inbound)\n                elif i == 2: pos = (dist, -1)    # East (Inbound)\n                else: pos = (-dist, 1)           # West (Inbound)\n                \n                # Marker based on vehicle type weight\n                color = '#0984e3' if v['weight'] == 1.0 else ('#fdcb6e' if v['weight'] > 1.0 else '#55efc4')\n                size = 10 + v['speed'] * 15 # Size reflects speed\n                self.ax.plot(pos[0], pos[1], marker='s', color=color, markersize=size, zorder=10)\n        \n        self.fig.canvas.draw()\n        self.fig.canvas.flush_events()\n        plt.pause(0.02)\n`
  }
];
